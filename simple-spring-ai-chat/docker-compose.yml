services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama
    restart: unless-stopped
    entrypoint: [ "/bin/sh", "-lc",
      "ollama serve & \
           sleep 5 && \
           ollama pull mistral && \
           ollama pull llava && \
           pkill ollama || true && \
           exec ollama serve"
    ]
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:11434/api/tags"]
      interval: 10s
      timeout: 5s
      retries: 10

volumes:
  ollama:


##  app:
##    # Your Spring Boot app (built as a local image or use Dockerfile)
##    build: .
##    container_name: spring-ai-app
##    depends_on:
##      ollama:
##        condition: service_healthy
##    environment:
##      SPRING_AI_OLLAMA_BASE_URL: "http://ollama:11434"
##    ports:
##      - "8080:8080"
##    restart: unless-stopped
#
#volumes:
#  ollama:
